---
title: "Create Chat"
api: "POST https://llamaapi.fly.dev/api/chat"
description: "This endpoint gets or creates a new chat."
---


### Request Body


<ParamField body="messages" type="object">
    This parameter represents a collection of messages that form the ongoing conversation.
</ParamField>

<ParamField body="functions" type="object">
    This parameter contains a list of functions for which the model can generate JSON inputs.
</ParamField>
<ParamField body="stream" type="boolean">
    When this option is enabled, the model will send partial message updates, similar to ChatGPT. Tokens will be transmitted as data-only server-sent events as they become available, and the streaming will conclude with a data: [DONE] marker.
</ParamField>
<ParamField body="function_call" type="string">
    This parameter governs the model's response to function calls. Choosing "none" indicates that the model will not invoke any functions and will respond directly to the end-user.
</ParamField>

### Response

<ResponseField name="choices" type="array">

<Expandable title="Toggle array">

<ResponseField name="index" type="number"> 

0

</ResponseField>

<ResponseField name="message" type="object">

<Expandable title="Toggle object">

<ResponseField name="role" type="string">

assistant

</ResponseField>

<ResponseField name="content" type="null">

null

</ResponseField>

<ResponseField name="function_call" type="object">

<Expandable title="Toggle object">

<ResponseField name="name" type="string">

get_current_weather

</ResponseField>  

<ResponseField name="arguments" type="object">

<Expandable title="Toggle object">

<ResponseField name="location" type="string">

Boston

</ResponseField>

<ResponseField name="days" type="number">

5

</ResponseField>

<ResponseField name="unit" type="string"> 

celsius

</ResponseField>

</Expandable>

</ResponseField>

</Expandable>  

</ResponseField>

</Expandable>

</ResponseField>  

<ResponseField name="finish_reason" type="string">

function_call

</ResponseField>

</Expandable>

</ResponseField>

<RequestExample>

```bash Example Request
curl --location --request POST 'https://llamaapi.fly.dev/api/chat' \
--header 'Content-Type: application/json' \
--header 'Authorization: Bearer <token>' \
--data-raw '{
    "messages": [
        {"role": "user", "content": "What is the weather like in Boston?"},
    ],
    "functions": [
        {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "days": {
                        "type": "number",
                        "description": "for how many days ahead you wants the forecast",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
            },
            "required": ["location", "days"],
        }
    ],
    "stream": False,
    "function_call": "get_current_weather",
}'
```

</RequestExample>

<ResponseExample>

```json Response
{
  "choices": [
    {
      "index": 0, 
      "message": {
        "role": "assistant", 
        "content": null, 
        "function_call": {
          "name": "get_current_weather", 
          "arguments": {
            "location": "Boston", 
            "days": 5, 
            "unit": "celsius"
          }
        }
      },
      "finish_reason": "function_call"
    }
  ]
}

```

</ResponseExample>

# Using the Python client
```python llama.py
import json
from llamaapi import LlamaAPI

# Initialize the llamaapi with your api_token
llama = LlamaAPI("<your_api_token>")

# Define your API request
api_request_json = {
    "messages": [
        {"role": "user", "content": "What is the weather like in Boston?"},
    ],
    "functions": [
        {
            "name": "get_current_weather",
            "description": "Get the current weather in a given location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "The city and state, e.g. San Francisco, CA",
                    },
                    "days": {
                        "type": "number",
                        "description": "for how many days ahead you wants the forecast",
                    },
                    "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]},
                },
            },
            "required": ["location", "days"],
        }
    ],
    "stream": False,
    "function_call": "get_current_weather",
}

# Make your request and handle the response
response = llama.run(api_request_json)
print(json.dumps(response.json(), indent=2))
```
